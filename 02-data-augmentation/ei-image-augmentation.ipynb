{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32-zMt7tZr3R"
      },
      "source": [
        "# Solution: Image Data Augmentation\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edgeimpulse/workshop-arduino-tinyml-roshambo/blob/main/02-data-augmentation/ei-image-augmentation.ipynb)\n",
        "\n",
        "This is a script for creating an augmented dataset for images. It transforms input images to create a series of augmented samples that are then uploaded to your Edge Impulse project.\n",
        "\n",
        "Upload your dataset as *dataset.zip* to */content/*. All of your samples should have the filename format `<label>.<unique-id>.png` (.jpg is also acceptable).\n",
        "\n",
        "Create a new project on [Edge Impulse](https://edgeimpulse.com/). Go to the dashboard of that project and copy your API key. Paste that key into the string value for `EI_API_KEY`. The final cell of this script will automatically upload the augmented dataset to your Edge Impulse project.\n",
        "\n",
        "Press **shift + enter** to execute each cell.\n",
        "\n",
        "The original images along with their transforms will be saved in the output directory. Each output file will be the original filename appended with \"_{num}\" where {num} is some incrementing value based on the total number of transforms performed per image.\n",
        "\n",
        "For example, if you have a file named `alpha.0.png`, it will become `alpha.0_0.png`. The first transform will be `alpha.0_1.png`, the second transform will be `alpha.0_2.png` and so on.\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: January 5, 2023<br>\n",
        "License: [Apache-2.0](apache.org/licenses/LICENSE-2.0)<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItoUNKszhkH7"
      },
      "outputs": [],
      "source": [
        "### Update Node.js to the latest stable version\n",
        "!npm cache clean -f\n",
        "!npm install -g n\n",
        "!n 16.18.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mru1ykhVhniO"
      },
      "outputs": [],
      "source": [
        "### Install required packages and tools\n",
        "!npm install -g --unsafe-perm edge-impulse-cli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RTimcB-ZoIT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import PIL\n",
        "\n",
        "import skimage.transform\n",
        "import skimage.util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zJCNZmEaCCN"
      },
      "outputs": [],
      "source": [
        "### Settings\n",
        "\n",
        "# Copy API here: Edge Impulse > your_project > Dashboard > Keys\n",
        "EI_API_KEY = \"ei_261c...\" \n",
        "\n",
        "# Path information\n",
        "HOME_PATH = \"/content\"                  # Location of the working directory\n",
        "DATASET_ZIP = \"/content/dataset.zip\"    # Name of the .zip file containing your original dataset\n",
        "DATASET_PATH = \"/content/dataset\"       # Upload your .csv samples to this directory\n",
        "OUT_PATH = \"/content/out\"               # Where output files go (will be deleted and recreated)\n",
        "OUT_ZIP = \"/content/out-augmented.zip\"  # Where to store the zipped output files\n",
        "\n",
        "# How to split the dataset\n",
        "TEST_RATIO = 0.2      # 20% reserved for test set, rest is for training\n",
        "\n",
        "# File format to use for new dataset\n",
        "IMG_EXT = \".png\"\n",
        "\n",
        "# Max batch size for uploading to Edge Impulse\n",
        "MAX_UPLOAD_BATCH_SIZE = 100\n",
        "\n",
        "# You are welcome to change the seed to get different augmentation effects\n",
        "SEED = 42\n",
        "random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vHNz_LN0klf"
      },
      "outputs": [],
      "source": [
        "### Use this to unzip the dataset folder\n",
        "# !rm -rf /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFRfqQdNYqyE"
      },
      "outputs": [],
      "source": [
        "### Unzip files to dataset directory\n",
        "%cd {HOME_PATH}\n",
        "!mkdir {DATASET_PATH}\n",
        "!unzip -q -d {DATASET_PATH} {DATASET_ZIP}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAZYWLFeB9vR"
      },
      "source": [
        "## Transform Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxh8f4JXgnTa"
      },
      "outputs": [],
      "source": [
        "### Example: Function to create 3 new flipped images of the input\n",
        "def create_flipped(img):\n",
        "\n",
        "  # Create a list of flipped images\n",
        "  flipped = []\n",
        "  flipped.append(np.fliplr(img))\n",
        "  flipped.append(np.flipud(img))\n",
        "  flipped.append(np.flipud(np.fliplr(img)))\n",
        "\n",
        "  return flipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96_3m50XhDww"
      },
      "outputs": [],
      "source": [
        "### Function to create new rotated images of the input\n",
        "def create_rotated(img, rotations):\n",
        "\n",
        "  # Create list of rotated images (keep 8-bit values)\n",
        "  rotated = []\n",
        "  for rot in rotations:\n",
        "    img_rot = skimage.transform.rotate(img, angle=rot, mode='edge', preserve_range=True)\n",
        "    img_rot = img_rot.astype(np.uint8)\n",
        "    rotated.append(img_rot)\n",
        "\n",
        "  return rotated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNmLBQtmg9rT"
      },
      "outputs": [],
      "source": [
        "### Function to create random scale/crop (zoom) images\n",
        "def create_random_zooms(img, scale_factor, num_crops):\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create scaled images (e.g. make the image bigger) and keep 8-bit values\n",
        "  img_scaled = skimage.transform.rescale(img, \n",
        "                                        scale=scale_factor, \n",
        "                                        anti_aliasing=True, \n",
        "                                        multichannel=True,\n",
        "                                        preserve_range=True)\n",
        "  img_scaled = img_scaled.astype(np.uint8)\n",
        "\n",
        "  # Get height and width of scaled image\n",
        "  s_h = img_scaled.shape[0]\n",
        "  s_w = img_scaled.shape[1]\n",
        "\n",
        "  # Create list of random zooms\n",
        "  zooms = []\n",
        "  for i in range(num_crops):\n",
        "    \n",
        "    # Randomly choose start of crop point\n",
        "    crop_y = round(random.random() * (s_h - height))\n",
        "    crop_x = round(random.random() * (s_w - width))\n",
        "\n",
        "    # Crop scaled image\n",
        "    zoom = img_scaled[crop_y:(crop_y + height), crop_x:(crop_x + width), :]\n",
        "\n",
        "    # Append zoomed image to list\n",
        "    zooms.append(zoom)\n",
        "\n",
        "  return zooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b55wy1q69-xY"
      },
      "outputs": [],
      "source": [
        "### Function to create a random set of translated images (no more than 1/4 of width or height away)\n",
        "def create_random_translations(img, num_translations):\n",
        "\n",
        "  # Get height and width of original image\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  # Create list of random translations\n",
        "  translations = []\n",
        "  for i in range(num_translations):\n",
        "  \n",
        "    # Choose random amount to translate (up to 1/4 image width, height) in either direction\n",
        "    tr_y = round((0.5 - random.random()) * (height / 2))\n",
        "    tr_x = round((0.5 - random.random()) * (width / 2))\n",
        "\n",
        "    # Perform translation to create new image\n",
        "    translation = skimage.transform.AffineTransform(translation=(tr_y, tr_x))\n",
        "    img_tr = skimage.transform.warp(img, translation, mode='edge', preserve_range=True)\n",
        "    img_tr = img_tr.astype(np.uint8)\n",
        "\n",
        "    # Append translated image to list\n",
        "    translations.append(img_tr)\n",
        "\n",
        "  return translations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad0IR6Pc_n9b"
      },
      "outputs": [],
      "source": [
        "### Function to add random noise to images\n",
        "def create_noisy(img, types, seed=None):\n",
        "\n",
        "  # Add noise of different types\n",
        "  noisy_imgs = []\n",
        "  for t in types:\n",
        "    noise = skimage.util.random_noise(img, mode=t, seed=seed)\n",
        "    noise = (noise * 255).astype(np.uint8)\n",
        "    noisy_imgs.append(noise)\n",
        "\n",
        "  return noisy_imgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaJR7hAOCEID"
      },
      "source": [
        "## Perform Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siLr8t4-qR9K"
      },
      "outputs": [],
      "source": [
        "### Delete output directory (if it exists) and recreate it\n",
        "if os.path.exists(OUT_PATH):\n",
        "  shutil.rmtree(OUT_PATH)\n",
        "os.makedirs(OUT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9ryKQeQaOKE"
      },
      "outputs": [],
      "source": [
        "### Function to open image and create a list of new transforms\n",
        "def create_transforms(file_path):\n",
        "\n",
        "  # Open the image\n",
        "  img = PIL.Image.open(file_path)\n",
        "\n",
        "  # Convert the image to a Numpy array (keep all color channels)\n",
        "  img_array = np.asarray(img)\n",
        "\n",
        "  # Add original image to front of list\n",
        "  img_tfs = []\n",
        "  img_tfs.append([img_array])\n",
        "\n",
        "  # Perform transforms (call your functions)\n",
        "  img_tfs.append(create_flipped(img_array))\n",
        "  img_tfs.append(create_flipped(img_array))\n",
        "  img_tfs.append(create_rotated(img_array, [45, 90, 135]))\n",
        "  img_tfs.append(create_random_zooms(img_array, 1.3, 2))\n",
        "  img_tfs.append(create_random_translations(img_array, 2))\n",
        "  img_tfs.append(create_noisy(img_array, ['gaussian', 's&p'], SEED))\n",
        "\n",
        "  # Flatten list of lists (to create one long list of images)\n",
        "  img_tfs = [img for img_list in img_tfs for img in img_list]\n",
        "\n",
        "  return img_tfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olOvOcyfbQ6m"
      },
      "outputs": [],
      "source": [
        "### Load all images, create transforms, and save in output directory\n",
        "\n",
        "# Go through each file in the unzipped directory\n",
        "for filename in os.listdir(DATASET_PATH):\n",
        "\n",
        "  # Skip the Jupyter Notebook checkpoints folder that sometimes gets added\n",
        "  if filename == \".ipynb_checkpoints\":\n",
        "    continue\n",
        "\n",
        "  # Parse the filename into label and unique ID\n",
        "  file_root = os.path.splitext(filename)[0]\n",
        "  label = file_root.split('.')[0]\n",
        "  uid = '.'.join(file_root.split('.')[1:])\n",
        "\n",
        "  # Do all transforms for that one image\n",
        "  file_path = os.path.join(DATASET_PATH, filename)\n",
        "  img_tfs = create_transforms(file_path)\n",
        "\n",
        "  # Save images to new files in output directory\n",
        "  for i, img in enumerate(img_tfs):\n",
        "\n",
        "    # Create a Pillow image from the Numpy array\n",
        "    img_pil = PIL.Image.fromarray(img)\n",
        "\n",
        "    # Construct filename (<original>_<transform_num>.<EXT>)\n",
        "    out_file_path = os.path.join(OUT_PATH, label + \".\" + uid + \"_\" + str(i) + IMG_EXT)\n",
        "\n",
        "    # Convert Numpy array to image and save as a file\n",
        "    img_pil = PIL.Image.fromarray(img)\n",
        "    img_pil.save(out_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWwxvzKxDJ18"
      },
      "outputs": [],
      "source": [
        "### Zip our new dataset (use '!' to call Linux commands)\n",
        "%cd {OUT_PATH}\n",
        "!zip -FS -r -q {OUT_ZIP} *\n",
        "%cd {HOME_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpN6KzichUo3"
      },
      "source": [
        "## Upload Dataset to Edge Impulse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pocn-wUK9qXZ"
      },
      "outputs": [],
      "source": [
        "### Shuffle/split the filenames and create lists of the full paths\n",
        "\n",
        "# Create list of files for one category\n",
        "paths = []\n",
        "for filename in os.listdir(OUT_PATH):\n",
        "  paths.append(os.path.join(OUT_PATH, filename))\n",
        "\n",
        "# Shuffle and divide into test and training sets\n",
        "random.shuffle(paths)\n",
        "num_test_samples = int(TEST_RATIO * len(paths))\n",
        "test_paths = paths[:num_test_samples]\n",
        "train_paths = paths[num_test_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTgzTVN_Abo5"
      },
      "outputs": [],
      "source": [
        "### Upload test set to Edge Impulse in mini batches\n",
        "for first in range(0, len(test_paths), MAX_UPLOAD_BATCH_SIZE):\n",
        "\n",
        "  # Construct one long string with all the paths of the mini batch\n",
        "  test_mini_batch = test_paths[first:(first + MAX_UPLOAD_BATCH_SIZE)]\n",
        "  print(f\"Uploading {len(test_mini_batch)} files. Number {first} to \" \\\n",
        "        f\"{first + MAX_UPLOAD_BATCH_SIZE} out of a total of {len(test_paths)}.\")\n",
        "  test_mini_batch = ['\"' + s + '\"' for s in test_mini_batch]\n",
        "  test_mini_batch = ' '.join(test_mini_batch)\n",
        "\n",
        "  # Upload to Edge Impulse\n",
        "  !edge-impulse-uploader \\\n",
        "  --category testing \\\n",
        "  --api-key {EI_API_KEY} \\\n",
        "  --silent \\\n",
        "  {test_mini_batch}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1x13HMjhUdq"
      },
      "outputs": [],
      "source": [
        "### Upload training set to Edge Impulse in mini batches\n",
        "for first in range(0, len(train_paths), MAX_UPLOAD_BATCH_SIZE):\n",
        "\n",
        "  # Construct one long string with all the paths of the mini batch\n",
        "  train_mini_batch = train_paths[first:(first + MAX_UPLOAD_BATCH_SIZE)]\n",
        "  print(f\"Uploading {len(train_mini_batch)} files. Number {first} to \" \\\n",
        "        f\"{first + MAX_UPLOAD_BATCH_SIZE} out of a total of {len(train_paths)}.\")\n",
        "  train_mini_batch = ['\"' + s + '\"' for s in train_mini_batch]\n",
        "  train_mini_batch = ' '.join(train_mini_batch)\n",
        "\n",
        "  # Upload to Edge Impulse\n",
        "  !edge-impulse-uploader \\\n",
        "  --category training \\\n",
        "  --api-key {EI_API_KEY} \\\n",
        "  --silent \\\n",
        "  {train_mini_batch}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paWwB5zZ9fRU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
